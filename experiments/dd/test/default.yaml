attention: luong
batch_size: 64
beam_size: 1
bidirectional: true
cell: gru
char: false
config: config/dd.yaml
data: data/trg_data/dd/
dec_num_layers: 1
dropout: 0.0
emb_size: 512
enc_num_layers: 1
epoch: 40
eval_interval: 674
gpus:
- 0
hidden_size: 512
learning_rate: 0.0003
learning_rate_decay: 0.5
length_norm: true
log: test
logF: experiments/dd/
max_grad_norm: 10
max_split: 0
max_time_step: 50
metrics:
- bleu
mode: train
model: seq2seq
module: seq2seq
num_processes: 4
optim: adam
pool_size: 0
pretrain: ''
refF: ''
restore: ''
save_interval: 674
scale: 1
schedule: false
schesamp: false
seed: 1234
selfatt: false
shared_vocab: true
split_num: 0
src_vocab_size: 18322
start_decay_at: 10
swish: false
tgt_vocab_size: 18322
unk: true
use_cuda: true
